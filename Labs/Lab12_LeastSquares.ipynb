{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPwmtl8ozgWUrOwV57TbBYl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cu-applied-math/appm-4600-numerics/blob/main/Labs/Lab12_LeastSquares.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 12: Least Squares\n",
        "\n",
        "This lab focuses on the problem\n",
        "$$\\min_{\\vec{x}\\in\\mathbb{R}^m}\\;\\|A\\vec{x}-\\vec{b}\\|_2$$\n",
        "where $A\\in\\mathbb{R}^{m\\times n}$, and $m\\ge n$ and $\\text{rank}(A)=n$.\n",
        "\n",
        "We'll make problems where we can check our answer, first creating a \"true\" $\\vec{x}_{\\text{true}}$, then set $\\vec{b}=A \\vec{x}_{\\text{true}}$ for a given $A$ matrix, and your job is to solve for\n",
        "$\\vec{x}_{\\text{estimate}}=\\text{argmin}_{\\vec{x}}\\|A\\vec{x}-\\vec{b}\\|_2$\n",
        "\n",
        "#### Learning objectives\n",
        "- Learn how to solve a least squares problem \"from scratch\" (well, partially from scratch)\n",
        "- Understand pros and cons of different methods\n",
        "  - Which ones require pivoting?\n",
        "  - Which ones are faster?\n",
        "  - Which ones are faster on multiple cores or a GPU?  (i.e., more parallelizable)\n",
        "  - Which ones are more accurate?\n",
        "  - Does this depend on conditioning of $A$? On its shape? (i.e., almost square vs very tall and skinny)\n",
        "\n",
        "#### Tasks\n",
        "1. Write at least **four** distinct implementations to solve the least-squares problem (the solutions have about implementations). The implementations can be similar to each other, but each variant should be non-trivial.  You **are** allowed to use linear algebra library functions, such as:\n",
        "    - `scipy.linalg.inverse`\n",
        "    - `scipy.linalg.solve` and all its variants (i.e., the different options for `assume_a`)\n",
        "    - `scipy.linalg.qr` and all its variants (i.e., pivoting or not)\n",
        "    - `scipy.linalg.solve_triangular` for forward/back substitution\n",
        "    - `scipy.linalg.qr_multiply`\n",
        "    - `scipy.linalg.svd`\n",
        "    - `scipy.linalg.lstsq` and all its variants (i.e., the different options for `lapack_driver`). Since this routine does everything for you, you may only count it as **one** of your implementations (that is, if you do different options for `lapack_driver`, those don't count as separate implementations).\n",
        "2. Use your implementations\n",
        "    - Try \"problem 0\", a small easy problem that is good for checking whether your code works\n",
        "    - Then try \"problem 1\" and \"problem 2\" which are larger and less well-conditioned. How well do the implementations work?  \n",
        "        - **Time** your code\n",
        "        - Also **record the error** in the $\\ell_\\infty$ norm, i.e., $\\|\\vec{x_{true}} - \\vec{x_{est}}\\|_\\infty$\n",
        "3. If you have time, try an implementation on the GPU. *We highly recommend that this part of the lab is done on google colab*\n",
        "    - Use pytorch (already installed on colab)\n",
        "    - Select a GPU runtime\n",
        "    - See the scaffolded code below\n",
        "\n",
        "#### Deliverables\n",
        "1. Code for at least 4 implementations, and...\n",
        "2. at least one sentence (or more) about some pros and cons of different methods.\n",
        "\n",
        "Put both these deliverables into the same PDF and upload to Canvas\n",
        "\n",
        "*APPM 4600. Copyright 2025 Department of Applied Mathematics, University of Colorado Boulder. Released under a BSD 3-clause license*"
      ],
      "metadata": {
        "id": "sgFygRTS5Vfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RJcWHZPZ5LhS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.linalg as sla"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: write at least **four** implementations to solve the least-squares problem\n",
        "\n"
      ],
      "metadata": {
        "id": "geE2BIDblDBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 0: use this for debugging\n",
        "problem_label = 'Problem 0'\n",
        "rng     = np.random.default_rng(12345)\n",
        "n       = 20\n",
        "m       = 40\n",
        "A       = rng.standard_normal( (m,n), dtype=np.double )\n",
        "xTrue   = rng.standard_normal(n)\n",
        "b       = A@xTrue\n",
        "print(f'Matrix is size {m} x {n}')\n",
        "print(f'Condition number of A is {np.linalg.cond(A):.2e}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9XE-H1ukmqr",
        "outputId": "c0a4c228-5ff0-4380-cf89-6dc319d412eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix is size 40 x 20\n",
            "Condition number of A is 3.78e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your solutions\n",
        "\n",
        "x = ... TODO ...\n",
        "\n",
        "err   = np.linalg.norm(x-xTrue,np.inf)\n",
        "print(f'Error is {err:.2e}')"
      ],
      "metadata": {
        "id": "578eOrA0lRpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Try solving some larger problems\n",
        "- Record the **error** in the infinity norm, and...\n",
        "- Record the **time** it takes\n",
        "\n",
        "To measure time, in jupyter/colab/iPython, you can use a line like\n",
        "\n",
        "`%time x = myFunction(...)`\n",
        "\n",
        "and it will time how long it takes `myFunction(...)` to run\n",
        "\n",
        "\n",
        "What **observations** can you make?\n",
        "\n",
        "Note that if you use `%time`, it will return both the:\n",
        "1. CPU time, which is the sum of how long all cores on the computer spend. So if you have 4 cores, and each core takes 3 seconds (and is fully utilized), the CPU time is 12 seconds.\n",
        "2. \"Wall\" time, which refers to \"wall clock\" time. This is the actual time elapsed from when you start to when you stop.\n",
        "\n",
        "If the CPU time is 12 seconds and the wall time is 3 seconds, this indicates that the code ran in parallel."
      ],
      "metadata": {
        "id": "U-i8EemsrqLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1\n",
        "problem_label = 'Problem 1'\n",
        "rng     = np.random.default_rng(12345)\n",
        "n       = int(5e3)\n",
        "m       = n+10\n",
        "# To give ourselves an added challenge (and to be fair for when we compare to the GPU),\n",
        "#   let's do this in single precision rather than double precision, so this means\n",
        "#   we start with about 8 digits of accuracy\n",
        "A       = rng.standard_normal( (m,n), dtype=np.single )\n",
        "xTrue   = rng.standard_normal(n)\n",
        "b       = A@xTrue\n",
        "print(f'Matrix is size {m} x {n}')\n",
        "print(f'Condition number of A is {np.linalg.cond(A):.2e}') # takes a bit of time to run! It's about 2e3 if n=5e3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY4d9uZA5ZaE",
        "outputId": "282bcd9b-aa02-4a7d-c859-777e69ebdfc7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix is size 5010 x 5000\n",
            "Condition number of A is 1.97e+03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 2\n",
        "problem_label = 'Problem 2'\n",
        "rng = np.random.default_rng(12345)\n",
        "\n",
        "n   = int(2e3)\n",
        "n2  = int(n/2)\n",
        "m   = int(1e4)\n",
        "A       = rng.standard_normal( (m,n2) )\n",
        "c       = 1e-2 # make this smaller, like 1e-4, to make the matrix more ill-conditioned\n",
        "A       = np.hstack(  (A,A+c*rng.standard_normal( (m,n2) )), dtype=np.single )\n",
        "xTrue   = rng.standard_normal(n)\n",
        "b       = A@xTrue\n",
        "print(f'Matrix is size {m} x {n}')\n",
        "print(f'Condition number of A is {np.linalg.cond(A):.2e}') # takes a bit of time to run! It's about 4.1e2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKhJRpYS5i12",
        "outputId": "8bfcdb5d-0faf-4f2d-dbb1-0ec30825fe92"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix is size 10000 x 2000\n",
            "Condition number of A is 4.14e+02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Try it on the GPU\n",
        "\n",
        "Restart the colab runtime and select a GPU runtime (or try a TPU!).  If you register for the Colab \"pro\" account (free for students and educators!) you'll get access to more/faster GPUs.\n",
        "\n",
        "We'll use PyTorch for our GPU computing.  You *can* run this just on the CPU also.  Some code is specific for either CPU or GPU, but most code runs on both.\n",
        "\n",
        "PyTorch has its own `torch.linalg` library, which is similar to (but not the same) as `numpy.linalg` and `scipy.linalg`.  It has GPU implementations, but lacks some of the fancier features that scipy has, and overall has fewer methods.\n",
        "\n",
        "For timing, you can still use `%time` for a single line, or `%%time` to time an entire cell. However, you need to make sure to call `torch.cuda.synchronize()` within the timed code, otherwise it won't time it properly (it will think that the code is done running when it's not really done)."
      ],
      "metadata": {
        "id": "LFxV2P8s5ktY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.linalg as tsla\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print('Device is ', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd2qdr225l65",
        "outputId": "c654f730-bcf7-41e6-e0b0-a469279b99ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device is  cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 0: use this for debugging\n",
        "problem_label = 'Problem 0'\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "n       = 20\n",
        "m       = 40\n",
        "A       = torch.randn(m,n,device=device) # by default it's single precision\n",
        "xTrue   = torch.randn(n,1,device=device)\n",
        "b       = A@xTrue\n",
        "print(f'Matrix is size {m} x {n}, device is {device}')\n",
        "print(f'Condition number of A is {tsla.cond(A):.2e}') # 1e3"
      ],
      "metadata": {
        "id": "deyZdZEKtY4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: try a GPU implementation\n",
        "\n",
        "# (note: you do NOT have to do a GPU implementation in order to get full credit for the lab - it's not one of the deliverables)"
      ],
      "metadata": {
        "id": "UcTlXnpux8wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem_label = 'Problem 1'\n",
        "torch.manual_seed(1234)\n",
        "n       = int(5e3)\n",
        "m       = n+10\n",
        "A       = torch.randn(m,n,device=device) # by default it's single precision\n",
        "xTrue   = torch.randn(n,1,device=device)\n",
        "b       = A@xTrue\n",
        "print(f'Matrix is size {m} x {n}, device is {device}')\n",
        "print(f'Condition number of A is {tsla.cond(A):.2e}') # 1e3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOWXr7vfIwbb",
        "outputId": "4c86f390-447f-46f9-81ce-279335ec44dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix is size 5010 x 5000, device is cpu\n",
            "Condition number of A is 1.73e+03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "problem_label = 'Problem 2'\n",
        "torch.manual_seed(0)\n",
        "\n",
        "n   = int(2e3)\n",
        "n2  = int(n/2)\n",
        "m   = int(1e4)\n",
        "A       = torch.randn(m,n2,device=device) # by default it's single precision\n",
        "A       = torch.hstack(  (A,A+1e-2*torch.randn(m,n2,device=device) ) )\n",
        "xTrue   = torch.randn(n,1,device=device)\n",
        "b       = A@xTrue\n",
        "print(f'Matrix is size {m} x {n}')\n",
        "print(f'Condition number of A is {tsla.cond(A):.2e}') # 4e2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1oLCITBLtwg",
        "outputId": "df620e9f-2b1b-476a-fb72-fe33b7aec159"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix is size 10000 x 2000\n",
            "Condition number of A is 4.14e+02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: do some tests on these larger/harder problems"
      ],
      "metadata": {
        "id": "FUV5BK00JiUH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}